import matplotlib.pylab as plt
import numpy as np

def sigmoid(x):
    return 1/(1+np.exp(-x))

# 0층에서 1층으로 진행하는 신경망
# 들어오는 신호는 2개
# 1층의 뉴런은 3개이므로
# 3개의 원소를 가지는 w가 2개여야 하므로
# 2x3 행렬의 W를 만들어준다

X = np.array([1.0,0.5])
W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])
B1 = np.array([0.1,0.2,0.3])

A1 = np.dot(X,W1) +B1
# 은닉층에서의 가중치 합을 a라고 한다.
# 이 a가 모인 행렬을 A라고 한다.
# 즉 A는 활성화 함수를 거치기 전의 값 
# x는 입력 신호 값이며
# w는 그에 해당하는 가중치이다
# 거기에 편향을 더하여 값을 구한다

Z1 = sigmoid(A1)
# z는 활성화 함수를 거친 값이다.

print(Z1)

# 1층에서 2층으로 진행하는 신경망
# 들어오는 신호는 3개
# 2층의 뉴런은 2개이므로
# 2개의 원소를 가지는 w가 3개여야 하므로
# 3x2 행렬의 W를 만들어준다

W2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])
B2 = np.array([0.1,0.2])

A2 = np.dot(Z1,W2) + B2
Z2 = sigmoid(A2)

# 2층에서 출력층으로 전달되는 신호
# 활성화 함수를 다르게 사용한다
# 항등함수를 사용하여 사용 유무와 관계없이
# 같은 값이 나오지만 흐름을 구현하기 위한 함수
# 실제 출력층에서는 σ(시그마)로 표현되는 
# 은닉층과는 다른 활성화 함수를 사용한다

def identify_function(x):
    return x

W3 = np.array([[0.1,0.3],[0.2,0.4]])
B3 = np.array([0.1,0.2])

A3 = np.dot(Z2,W3) + B3
Y = identify_function(A3)

